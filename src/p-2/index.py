from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional, Annotated, Literal
import uuid
from langchain_core.messages import HumanMessage
from langchain_core.tools import tool
from langchain_core.messages import SystemMessage
from contextlib import asynccontextmanager
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, START, MessagesState, END
from langgraph.checkpoint.memory import InMemorySaver
from .config import get_config, validate_environment, setup_output_directory
import json

# å…¨å±€å˜é‡å­˜å‚¨ç³»ç»Ÿå®ä¾‹å’Œä¼šè¯
# programming_system = None
active_sessions: Dict[str, Dict[str, Any]] = {}

notebook_structure = {
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": str(uuid.uuid4())  # è‡ªåŠ¨åˆ†é…UUID
            },
            "source":["## æ¬¢è¿è¿›å…¥ ModelWhale Notebook  \n\nè¿™é‡Œä½ å¯ä»¥ç¼–å†™ä»£ç ï¼Œæ–‡æ¡£  \n\n### å…³äºæ–‡ä»¶ç›®å½•  \n\n\n**project**ï¼šproject ç›®å½•æ˜¯æœ¬é¡¹ç›®çš„å·¥ä½œç©ºé—´ï¼Œå¯ä»¥æŠŠå°†é¡¹ç›®è¿è¡Œæœ‰å…³çš„æ‰€æœ‰æ–‡ä»¶æ”¾åœ¨è¿™é‡Œï¼Œç›®å½•ä¸­æ–‡ä»¶çš„å¢ã€åˆ ã€æ”¹æ“ä½œéƒ½ä¼šè¢«ä¿ç•™  \n\n\n**input**ï¼šinput ç›®å½•æ˜¯æ•°æ®é›†çš„æŒ‚è½½ä½ç½®ï¼Œæ‰€æœ‰æŒ‚è½½è¿›é¡¹ç›®çš„æ•°æ®é›†éƒ½åœ¨è¿™é‡Œï¼ŒæœªæŒ‚è½½æ•°æ®é›†æ—¶ input ç›®å½•è¢«éšè—  \n\n\n**temp**ï¼štemp ç›®å½•æ˜¯ä¸´æ—¶ç£ç›˜ç©ºé—´ï¼Œè®­ç»ƒæˆ–åˆ†æè¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸å¿…è¦æ–‡ä»¶å¯ä»¥å­˜æ”¾åœ¨è¿™é‡Œï¼Œç›®å½•ä¸­çš„æ–‡ä»¶ä¸ä¼šä¿å­˜"]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

# å®šä¹‰æ ‡å‡†çš„LangChainå·¥å…·å‡½æ•°
@tool
def gen_notebook(
    notebook_name: Annotated[str, Field(description="Notebookæ–‡ä»¶åï¼ˆåŒ…å«.ipynbåç¼€ï¼‰")],
    notebook: Annotated[Optional[str], Field(description="å®Œæ•´çš„notebookç»“æ„ï¼Œå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONå­—ç¬¦ä¸²æ ¼å¼", default=None)]
) -> str:
    """ç”Ÿæˆä¸€ä¸ªæ–°çš„Jupyter Notebookæ–‡ä»¶"""
    return f"ç”Ÿæˆnotebook: {notebook_name}"

@tool  
def add_cell(
    filename: Annotated[str, Field(description="Notebookæ–‡ä»¶å")],
    content: Annotated[str, Field(description="å•å…ƒæ ¼å†…å®¹")],
    cell_type: Annotated[str, Field(description="å•å…ƒæ ¼ç±»å‹", default="code")] = "code",
    cell_index: Annotated[int, Field(description="æ’å…¥ä½ç½®ï¼ˆ-1è¡¨ç¤ºæ·»åŠ åˆ°æœ«å°¾ï¼‰", default=-1)] = -1
) -> str:
    """å‘Notebookæ·»åŠ å•å…ƒæ ¼ï¼ˆä»£ç æˆ–Markdownï¼‰"""
    return f"æ·»åŠ cellåˆ° {filename}: {cell_type} cell with content: {content[:50]}..."



@tool
def update_cell_by_id(
    filename: Annotated[str, Field(description="Notebookæ–‡ä»¶å")],
    cell_id: Annotated[str, Field(description="å•å…ƒæ ¼UUID")],
    new_content: Annotated[str, Field(description="æ–°çš„å•å…ƒæ ¼å†…å®¹")]
) -> str:
    """é€šè¿‡UUIDæ›´æ–°Notebookä¸­çš„å•å…ƒæ ¼å†…å®¹"""
    return f"æ›´æ–°cell {cell_id} in {filename}: {new_content[:50]}..."

@tool
def delete_cell_by_id(
    filename: Annotated[str, Field(description="Notebookæ–‡ä»¶å")],
    cell_id: Annotated[str, Field(description="è¦åˆ é™¤çš„å•å…ƒæ ¼UUID")]
) -> str:
    """é€šè¿‡UUIDåˆ é™¤Notebookä¸­çš„å•å…ƒæ ¼"""
    return f"åˆ é™¤cell {cell_id} from {filename}"

@tool
def run_notebook(
    filename: Annotated[str, Field(description="è¦è¿è¡Œçš„Notebookæ–‡ä»¶å")],
    cells: Annotated[List[str], Field(description="éœ€è¦è¿è¡Œçš„ä»£ç cell IDåˆ—è¡¨ï¼Œè‹¥ä¸ºç©ºåˆ™è¿è¡Œå…¨éƒ¨ä»£ç å•å…ƒæ ¼", default_factory=list)] = None
) -> str:
    """è¿è¡Œnotebookä¸­çš„ä»£ç å•å…ƒæ ¼ï¼Œè¿”å›è¿è¡Œåçš„notebookå†…å®¹"""
    return f"è¿è¡Œnotebook {filename}, cells: {cells or 'all'} - æ‰§è¡Œå®Œæˆï¼Œè¿”å›notebookå†…å®¹ä»¥ä¾›æ£€æŸ¥è¿è¡Œç»“æœå’Œé”™è¯¯"

def create_mock_programming_assistant():
    """åˆ›å»ºæ¨¡æ‹Ÿæ‰§è¡Œçš„NotebookAgentç³»ç»Ÿ"""
    config = get_config("notebook_agent")  # ä½¿ç”¨NotebookAgenté…ç½®
    openai_config = get_config("openai")
    
    llm = ChatOpenAI(
        model=openai_config["model"],
        api_key=openai_config["api_key"],
        base_url=openai_config["base_url"],
        temperature=openai_config["temperature"]
    )
    
    # ç»‘å®šNotebookAgentçš„å·¥å…·schema
    llm_with_tools = llm.bind_tools([
        gen_notebook,
        add_cell,
        update_cell_by_id,
        delete_cell_by_id,
        run_notebook
    ])
    
    # åˆ›å»ºcheckpointer
    checkpointer = InMemorySaver()
    
    # åˆ›å»ºå¸¦ç³»ç»Ÿæ¶ˆæ¯çš„LLM
    system_message = SystemMessage(content="""ä½ æ˜¯Jupyter Notebookä¸“å®¶ï¼Œç®¡ç†æœ‰çŠ¶æ€çš„Notebookç¯å¢ƒã€‚

é‡è¦ï¼š
- ä½ å¿…é¡»æ—¢æä¾›æ¸…æ™°çš„æ–‡å­—å›å¤ï¼Œåˆè°ƒç”¨é€‚å½“çš„å·¥å…·ã€‚æ°¸è¿œä¸è¦åªè°ƒç”¨å·¥å…·è€Œä¸è¯´è¯ã€‚
- ä¸è¦ç¼–é€ æ•°æ®ï¼Œä¸è¦ç¼–é€ ç»“æœï¼Œä¸€åˆ‡åˆ†æå’Œæ€»ç»“è¦åŸºäºå®é™…ç»“æœã€‚

å¯¹è¯åŸåˆ™ï¼š
1. é¦–å…ˆç†è§£ç”¨æˆ·éœ€æ±‚å¹¶ç¡®è®¤
2. è§£é‡Šä½ çš„è®¡åˆ’å’Œæ­¥éª¤
3. è°ƒç”¨å·¥å…·å®Œæˆä»»åŠ¡
4. æ€»ç»“å®Œæˆçš„å·¥ä½œ

å·¥å…·ï¼š
- gen_notebookï¼šç”Ÿæˆå®Œæ•´çš„notebookæ–‡ä»¶
- add_cellï¼šæ·»åŠ cellåˆ°æŒ‡å®šä½ç½®
- update_cell_by_idï¼šé€šè¿‡IDæ›´æ–°ä¿®æ”¹cellå†…å®¹
- delete_cell_by_idï¼šé€šè¿‡IDåˆ é™¤cell
- run_notebookï¼šè¿è¡Œnotebookä¸­çš„ä»£ç å•å…ƒæ ¼ï¼Œè¿”å›è¿è¡Œåçš„notebookå†…å®¹ä»¥ä¾›æ£€æŸ¥è¿è¡Œç»“æœå’Œé”™è¯¯

ä»£ç ç”ŸæˆåŸåˆ™ï¼š
- è¯·è®°ä½Notbeookæ˜¯æœ‰çŠ¶æ€çš„ï¼Œéœ€è¦è€ƒè™‘cellçš„é¡ºåºå’Œä¾èµ–å…³ç³»ã€‚
- ä¸è¦é‡å¤å®šä¹‰ä¹‹å‰cellä¸­çš„å˜é‡ã€å‡½æ•°ã€ç±»ç­‰ï¼Œä¸è¦é‡å¤å¯¼å…¥åŒ…ã€‚
- ä½ æ— æ³•ç›´æ¥"çœ‹åˆ°"å›¾ç‰‡ï¼Œæ‰€ä»¥ç”»å›¾åŒæ—¶å°½é‡æ‰“å°æ•°æ®æˆ–ç›¸å…³ä¿¡æ¯ã€‚

è®°ä½ï¼šå§‹ç»ˆå…ˆè§£é‡Šï¼Œå†è¡ŒåŠ¨ï¼Œæœ€åæ€»ç»“ã€‚""")
    
    def agent_node(state: MessagesState):
        """Notebookä»£ç†èŠ‚ç‚¹ - è‡ªåŠ¨å¤„ç†ç³»ç»Ÿæ¶ˆæ¯"""
        messages = state["messages"]
        if not messages or not (hasattr(messages[0], 'type') and messages[0].type == 'system'):
            messages = [system_message] + messages
        
        response = llm_with_tools.invoke(messages)
        return {"messages": [response]}

    
    # åˆ›å»ºçŠ¶æ€å›¾ - æœ€ç®€æ´çš„å†™æ³•
    graph = (
        StateGraph(MessagesState)
        .add_node("agent", agent_node)
        .add_edge(START, "agent") 
        .add_edge("agent", END)
        .compile(checkpointer=checkpointer)
    )
    
    return graph

# @asynccontextmanager
# async def lifespan(app: FastAPI):
"""ç³»ç»Ÿç”Ÿå‘½å‘¨æœŸäº‹ä»¶å¤„ç†å™¨"""
global programming_system

print("ğŸ¤– æ¨¡æ‹Ÿç¼–ç¨‹åŠ©æ‰‹APIå¯åŠ¨ä¸­...")

# éªŒè¯ç¯å¢ƒé…ç½®
if not validate_environment():
    raise RuntimeError("ç¯å¢ƒé…ç½®éªŒè¯å¤±è´¥")

# è®¾ç½®è¾“å‡ºç›®å½•
setup_output_directory()

# åˆ›å»ºæ¨¡æ‹Ÿç³»ç»Ÿ
programming_system = create_mock_programming_assistant()


print("âœ… æ¨¡æ‹Ÿç¼–ç¨‹åŠ©æ‰‹APIå¯åŠ¨å®Œæˆï¼")

# yield

# æ¸…ç†èµ„æº
# print("ğŸ‘‹ æ¨¡æ‹Ÿç¼–ç¨‹åŠ©æ‰‹APIå…³é—­ä¸­...")

# åˆå§‹åŒ–FastAPIåº”ç”¨
# app = FastAPI(
#     title="æ¨¡æ‹Ÿç¼–ç¨‹åŠ©æ‰‹API",
#     description="åŸºäºLLMçš„ç¼–ç¨‹åŠ©æ‰‹æœåŠ¡ï¼ˆä¸å®é™…æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼‰",
#     version="1.0.0",
#     lifespan=lifespan
# )

# è¯·æ±‚å’Œå“åº”æ¨¡å‹
class UserRequest(BaseModel):
    threadid: str
    role: Literal["user"] = "user"
    content: str

class ToolRequest(BaseModel):
    threadid: str
    role: Literal["tool"] = "tool"
    content: str
    tool_call_id: str
    status: Literal["success", "error"] = "success"

class ChatRequest(BaseModel):
    """ç»Ÿä¸€çš„èŠå¤©è¯·æ±‚ï¼Œæ”¯æŒç”¨æˆ·æ¶ˆæ¯å’Œå·¥å…·ç»“æœ"""
    threadid: str
    role: Literal["user", "tool"]
    content: str
    tool_call_id: Optional[str] = None
    status: Optional[Literal["success", "error"]] = None

class ToolCall(BaseModel):
    function: Dict[str, Any]
    id: str
    type: str

class ChatResponse(BaseModel):
    role: Literal["assistant"] = "assistant"
    content: str
    id: str
    type: str = ""  # é»˜è®¤å€¼ï¼Œä¼šåœ¨æ¨¡å‹éªŒè¯æ—¶è¢«æ­£ç¡®è®¾ç½®
    tool_calls: List[ToolCall] = []
    
    @classmethod
    def create(cls, content: str, id: str, tool_calls: List[ToolCall] = None):
        """åˆ›å»ºChatResponseå®ä¾‹ï¼Œè‡ªåŠ¨è®¾ç½®typeå­—æ®µ"""
        if tool_calls is None:
            tool_calls = []
        
        response_type = "tool" if tool_calls else "ai"
        
        return cls(
            content=content,
            id=id,
            type=response_type,
            tool_calls=tool_calls
        )

def extract_ai_message_from_updates(updates: List[Any]) -> Dict[str, Any]:
    """ä»æ›´æ–°ä¸­æå–æœ€åä¸€ä¸ªAIæ¶ˆæ¯çš„å®Œæ•´ä¿¡æ¯"""
    last_ai_message = None
    
    for update in updates:
        if isinstance(update, tuple):
            # å¤„ç†å­å›¾æ›´æ–°
            _, update_content = update
        else:
            update_content = update
            
        for node_name, node_update in update_content.items():
            if isinstance(node_update, dict) and "messages" in node_update:
                messages = node_update["messages"]
                if messages:
                    last_message = messages[-1]
                    # åªå¤„ç†AIæ¶ˆæ¯
                    if hasattr(last_message, 'type') and last_message.type == 'ai':
                        last_ai_message = last_message
                    elif hasattr(last_message, '__class__') and 'AIMessage' in last_message.__class__.__name__:
                        last_ai_message = last_message
    
    if not last_ai_message:
        return {
            "content": "å¤„ç†å®Œæˆ",
            "id": str(uuid.uuid4()),
            "tool_calls": [],
            "type": "ai"
        }
    
    # è°ƒè¯•ï¼šæ‰“å°AIæ¶ˆæ¯çš„è¯¦ç»†ä¿¡æ¯
    print(f"AI Message type: {type(last_ai_message)}")
    print(f"AI Message content repr: {repr(getattr(last_ai_message, 'content', 'No content'))}")
    print(f"AI Message content type: {type(getattr(last_ai_message, 'content', None))}")
    print(f"AI Message full dict: {last_ai_message.__dict__ if hasattr(last_ai_message, '__dict__') else 'No dict'}")
    if hasattr(last_ai_message, 'tool_calls'):
        print(f"Tool calls count: {len(last_ai_message.tool_calls) if last_ai_message.tool_calls else 0}")
        if last_ai_message.tool_calls:
            for i, tc in enumerate(last_ai_message.tool_calls):
                print(f"Tool call {i}: type={type(tc)}, content={tc}")
    else:
        print("No tool_calls attribute")
    
    # æå–æ¶ˆæ¯ä¿¡æ¯
    result = {
        "content": getattr(last_ai_message, 'content', ''),
        "id": getattr(last_ai_message, 'id', str(uuid.uuid4())),
        "tool_calls": [],
        "type": "ai"
    }
    
    # æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
    if hasattr(last_ai_message, 'tool_calls') and last_ai_message.tool_calls:
        for tool_call in last_ai_message.tool_calls:
            # å¤„ç†ä¸åŒçš„tool_callç»“æ„
            if hasattr(tool_call, '__dict__'):
                # å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•è·å–å±æ€§
                tool_name = getattr(tool_call, 'name', '') or getattr(tool_call, 'function', {}).get('name', '')
                tool_args = getattr(tool_call, 'args', {}) or getattr(tool_call, 'function', {}).get('arguments', {})
                tool_id = getattr(tool_call, 'id', str(uuid.uuid4()))
                tool_type = getattr(tool_call, 'type', 'function')
            elif isinstance(tool_call, dict):
                # å¦‚æœæ˜¯å­—å…¸ï¼Œç›´æ¥è®¿é—®
                tool_name = tool_call.get('name', '') or tool_call.get('function', {}).get('name', '')
                tool_args = tool_call.get('args', {}) or tool_call.get('function', {}).get('arguments', {})
                tool_id = tool_call.get('id', str(uuid.uuid4()))
                tool_type = tool_call.get('type', 'function')
            else:
                # å…¶ä»–æƒ…å†µï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²æŸ¥çœ‹
                print(f"Unexpected tool_call type: {type(tool_call)}, content: {tool_call}")
                continue
            
            # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯gen_notebookä¸”æ²¡æœ‰notebookå‚æ•°ï¼Œæ·»åŠ é»˜è®¤å€¼
            if tool_name == 'gen_notebook':
                tool_args['notebook_name'] = tool_args['notebook_name'].split('.')[0] + '_' + str(uuid.uuid4()).split('-')[1] + '.ipynb'
                if 'notebook' not in tool_args or not tool_args['notebook']:
                    tool_args['notebook'] = json.dumps(notebook_structure)  # ç¡®ä¿æ˜¯JSONæ ¼å¼
                    print(f"Added default notebook_structure to gen_notebook call")
            
            tool_call_dict = {
                "function": {
                    "arguments": tool_args,
                    "name": tool_name
                },
                "id": tool_id,
                "type": 'function'
            }
            result["tool_calls"].append(tool_call_dict)
    
    return result

# @app.post("/", response_model=ChatResponse)
# async def chat(request: ChatRequest):
def invoke(request):
    """ç»Ÿä¸€çš„å¯¹è¯æ¥å£ï¼Œæ”¯æŒç”¨æˆ·æ¶ˆæ¯å’Œå·¥å…·ç»“æœ"""
    global programming_system, active_sessions
    
    if not programming_system:
        raise HTTPException(status_code=500, detail="ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    # ä½¿ç”¨threadidä½œä¸ºä¼šè¯æ ‡è¯†
    config = {"configurable": {"thread_id": request["threadid"]}}
    
    try:
        print(f"ğŸ” å¤„ç†æ¶ˆæ¯: {request['content']}")
        print(f"ğŸ” æ¶ˆæ¯è§’è‰²: {request['role']}")
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        
        if request["role"] == "tool":
            # å¦‚æœæ˜¯å·¥å…·ç»“æœï¼Œæ„å»ºToolMessage
            if not request["tool_call_id"]:
                raise HTTPException(status_code=400, detail="å·¥å…·æ¶ˆæ¯ç¼ºå°‘tool_call_id")
            
            from langchain_core.messages import ToolMessage
            tool_message = ToolMessage(
                content=request["content"],
                tool_call_id=request["tool_call_id"]
            )
            messages.append(tool_message)
            print(f"ğŸ” æ„å»ºäº†å·¥å…·æ¶ˆæ¯ï¼Œtool_call_id: {request['tool_call_id']}")
        else:
            # å¦‚æœæ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œæ„å»ºHumanMessage
            messages.append(HumanMessage(content=request["content"]))
            print(f"ğŸ” æ„å»ºäº†ç”¨æˆ·æ¶ˆæ¯")
        
        # æ”¶é›†æ‰€æœ‰æ›´æ–°
        updates = []
        
        for chunk in programming_system.stream(
            {"messages": messages},
            config=config
        ):
            updates.append(chunk)
        
        print(f"ğŸ” æ”¶é›†åˆ° {len(updates)} ä¸ªæ›´æ–°")
        
        # æå–AIæ¶ˆæ¯
        ai_message = extract_ai_message_from_updates(updates)
        print(f"ğŸ” æå–AIæ¶ˆæ¯å®Œæˆï¼Œcontenté•¿åº¦: {len(ai_message.get('content', ''))}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        has_tool_calls = len(ai_message["tool_calls"]) > 0
        print(f"ğŸ” å·¥å…·è°ƒç”¨æ•°é‡: {len(ai_message['tool_calls'])}")
        
        print(f"ğŸ” å‡†å¤‡æ„å»ºå“åº”")
        
        # å®‰å…¨åœ°æ„å»ºToolCallå¯¹è±¡
        tool_call_objects = []
        for tc in ai_message["tool_calls"]:
            try:
                tool_call_objects.append(ToolCall(**tc))
            except Exception as tc_error:
                print(f"âŒ æ„å»ºToolCallå¯¹è±¡å¤±è´¥: {tc_error}, åŸå§‹æ•°æ®: {tc}")
                # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼æ„å»º
                tool_call_objects.append(ToolCall(
                    function=tc.get("function", {}),
                    id=tc.get("id", str(uuid.uuid4())),
                    type=tc.get("type", "function")
                ))
        
        response = ChatResponse.create(
            content=ai_message["content"],
            id=ai_message["id"],
            tool_calls=tool_call_objects
        )
        
        print(f"âœ… å“åº”æ„å»ºå®Œæˆ")
        return response.model_dump()
            
    except Exception as e:
        print(f"âŒ å¤„ç†è¯·æ±‚å‡ºé”™: {str(e)}")
        print(f"âŒ é”™è¯¯ç±»å‹: {type(e)}")
        import traceback
        print(f"âŒ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        
        # æ¸…ç†ä¼šè¯
        if request["threadid"] in active_sessions:
            del active_sessions[request["threadid"]]
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")

# @app.get("/threads")
# async def get_active_threads():
#     """è·å–æ´»è·ƒçº¿ç¨‹åˆ—è¡¨"""
#     return {
#         "active_threads": list(active_sessions.keys()),
#         "count": len(active_sessions)
#     }

# @app.delete("/threads/{threadid}")
# async def clear_thread(threadid: str):
#     """æ¸…ç†æŒ‡å®šçº¿ç¨‹"""
#     if threadid in active_sessions:
#         del active_sessions[threadid]
#         return {"message": f"çº¿ç¨‹ {threadid} å·²æ¸…ç†"}
#     else:
#         raise HTTPException(status_code=404, detail="çº¿ç¨‹ä¸å­˜åœ¨")

# @app.get("/info")
# async def root():
#     """è¿”å›APIä¿¡æ¯"""
#     return {
#         "message": "æ¨¡æ‹ŸNotebookAgent API",
#         "version": "1.0.0",
#         "description": "åŸºäºNotebookAgentçš„ç¼–ç¨‹åŠ©æ‰‹æœåŠ¡ï¼ŒLLMç”Ÿæˆå·¥å…·è°ƒç”¨ä½†ä¸å®é™…æ‰§è¡Œ",
#         "agent_info": {
#             "type": "notebook_agent",
#             "prompt": "ä½¿ç”¨åŸå§‹NotebookAgentçš„promptå’Œå·¥å…·",
#             "capabilities": [
#                 "Notebookç®¡ç†ï¼ˆåˆ›å»ºã€è¯»å–ã€ä¿®æ”¹ï¼‰",
#                 "ä»£ç å•å…ƒæ ¼è¿è¡Œ",
#                 "ä»£ç ç”Ÿæˆå’Œåˆ†æ",
#                 "ç”¨æˆ·äº¤äº’ç®¡ç†"
#             ]
#         },
#         "endpoints": {
#             "chat": "POST /chat - å‘é€æ¶ˆæ¯ï¼Œè·å–åŒ…å«tool_callsçš„å“åº”",
#             "sessions": "GET /sessions - æŸ¥çœ‹æ´»è·ƒä¼šè¯",
#             "clear_session": "DELETE /sessions/{session_id} - æ¸…ç†ä¼šè¯"
#         },
#         "usage": {
#             "chat": "å‘é€ {'message': 'ä½ çš„æ¶ˆæ¯', 'session_id': 'å¯é€‰çš„ä¼šè¯ID'} åˆ° /chat",
#             "note": "ç³»ç»Ÿä½¿ç”¨NotebookAgentçš„å®Œæ•´promptå’Œå·¥å…·ï¼Œä½†ä¸å®é™…æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œæ‰€æœ‰å·¥å…·è°ƒç”¨ä¿¡æ¯è¿”å›åœ¨tool_callså­—æ®µä¸­"
#         }
#     }

# è¿è¡ŒæœåŠ¡çš„ä¸»å‡½æ•°
# if __name__ == "__main__":
#     import uvicorn
#     uvicorn.run(app, host="0.0.0.0", port=8080)